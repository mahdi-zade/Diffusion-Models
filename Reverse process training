"""
Corresponds to Algorithm 1 from (Ho et al., 2020).
"""

def get_loss(self batch, batch_idx):  # self_batch corresponds to x0(image sample) equation 1

  # Get a random time step for each image in the batch
  ts = torch.randint(0, self.t_range, [batch.shape[0]], device=self.device)  # 1<ts<T equation 2
  
  noise_imgs = []
  # Generate noise, one for each image in the batch
  epsilons = torch.randn(batch.shape, device=self.device) #equation 3

  # create the noisy version of each image
  for i in range(len(ts)):
    a_hat = self.alpha_bar(ts[i])
    noise_imgs.append(
      (math.sqrt(a_hat) * batch[i]) + (math.sqrt(1 - a_hat) * epsilons[i])
    )
  
  noise_imgs = torch.stack(noise_imgs, dim=0)

  # Run the noisy images through the U-Net, to get the predicted noise
  e_theta = self.forward(noise_imgs, ts) #e_theta in equation 5 
  
  # Calculate the loss, that is, the MSE between the predicted noise and the actual noise
  loss = nn. functional.mse_loss(
    e_theta.reshape(-1, self.in_size), epsilons.reshape(-1, self.in_size) #equation 5
  )
  return loss
